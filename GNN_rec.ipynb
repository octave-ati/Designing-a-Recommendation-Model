{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d222c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics as st\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "70450f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of click files:  385\n",
      "Concatenating click files...\n",
      "(2988181, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>session_start</th>\n",
       "      <th>session_size</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1506825423271737</td>\n",
       "      <td>1506825423000</td>\n",
       "      <td>2</td>\n",
       "      <td>157541</td>\n",
       "      <td>1506826828020</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1506825423271737</td>\n",
       "      <td>1506825423000</td>\n",
       "      <td>2</td>\n",
       "      <td>68866</td>\n",
       "      <td>1506826858020</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1506825426267738</td>\n",
       "      <td>1506825426000</td>\n",
       "      <td>2</td>\n",
       "      <td>235840</td>\n",
       "      <td>1506827017951</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1506825426267738</td>\n",
       "      <td>1506825426000</td>\n",
       "      <td>2</td>\n",
       "      <td>96663</td>\n",
       "      <td>1506827047951</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1506825435299739</td>\n",
       "      <td>1506825435000</td>\n",
       "      <td>2</td>\n",
       "      <td>119592</td>\n",
       "      <td>1506827090575</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id        session_id  session_start session_size click_article_id  \\\n",
       "0       0  1506825423271737  1506825423000            2           157541   \n",
       "1       0  1506825423271737  1506825423000            2            68866   \n",
       "2       1  1506825426267738  1506825426000            2           235840   \n",
       "3       1  1506825426267738  1506825426000            2            96663   \n",
       "4       2  1506825435299739  1506825435000            2           119592   \n",
       "\n",
       "  click_timestamp click_environment click_deviceGroup click_os click_country  \\\n",
       "0   1506826828020                 4                 3       20             1   \n",
       "1   1506826858020                 4                 3       20             1   \n",
       "2   1506827017951                 4                 1       17             1   \n",
       "3   1506827047951                 4                 1       17             1   \n",
       "4   1506827090575                 4                 1       17             1   \n",
       "\n",
       "  click_region click_referrer_type  \n",
       "0           20                   2  \n",
       "1           20                   2  \n",
       "2           16                   2  \n",
       "3           16                   2  \n",
       "4           24                   2  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLICK_PATH = 'Data/clicks/'\n",
    "\n",
    "click_files = [CLICK_PATH + f for f in os.listdir(CLICK_PATH)]\n",
    "\n",
    "click_files.sort()\n",
    "\n",
    "print(\"Number of click files: \", len(click_files))\n",
    "\n",
    "print(\"Concatenating click files...\")\n",
    "\n",
    "click_dfs = [pd.read_csv(x) for x in click_files]\n",
    "\n",
    "click_df = pd.concat(click_dfs, axis=0, ignore_index=True)\n",
    "\n",
    "print(click_df.shape)\n",
    "click_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8c9296d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>session_start</th>\n",
       "      <th>session_size</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.988181e+06</td>\n",
       "      <td>2.988181e+06</td>\n",
       "      <td>2.988181e+06</td>\n",
       "      <td>2.988181e+06</td>\n",
       "      <td>2.988181e+06</td>\n",
       "      <td>2.988181e+06</td>\n",
       "      <td>2.988181e+06</td>\n",
       "      <td>2.988181e+06</td>\n",
       "      <td>2.988181e+06</td>\n",
       "      <td>2.988181e+06</td>\n",
       "      <td>2.988181e+06</td>\n",
       "      <td>2.988181e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.079478e+05</td>\n",
       "      <td>1.507472e+15</td>\n",
       "      <td>1.507472e+12</td>\n",
       "      <td>3.901885e+00</td>\n",
       "      <td>1.949226e+05</td>\n",
       "      <td>1.507474e+12</td>\n",
       "      <td>3.942652e+00</td>\n",
       "      <td>1.819306e+00</td>\n",
       "      <td>1.327760e+01</td>\n",
       "      <td>1.357656e+00</td>\n",
       "      <td>1.831331e+01</td>\n",
       "      <td>1.838981e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.364836e+04</td>\n",
       "      <td>3.855245e+11</td>\n",
       "      <td>3.855245e+08</td>\n",
       "      <td>3.929941e+00</td>\n",
       "      <td>9.076842e+04</td>\n",
       "      <td>3.858510e+08</td>\n",
       "      <td>3.396804e-01</td>\n",
       "      <td>1.042214e+00</td>\n",
       "      <td>6.881718e+00</td>\n",
       "      <td>1.725861e+00</td>\n",
       "      <td>7.064006e+00</td>\n",
       "      <td>1.156356e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.506825e+15</td>\n",
       "      <td>1.506825e+12</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.506827e+12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.034100e+04</td>\n",
       "      <td>1.507124e+15</td>\n",
       "      <td>1.507124e+12</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.242280e+05</td>\n",
       "      <td>1.507127e+12</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.622900e+04</td>\n",
       "      <td>1.507493e+15</td>\n",
       "      <td>1.507493e+12</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.023810e+05</td>\n",
       "      <td>1.507495e+12</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.100000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.632610e+05</td>\n",
       "      <td>1.507749e+15</td>\n",
       "      <td>1.507749e+12</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>2.770670e+05</td>\n",
       "      <td>1.507751e+12</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.228960e+05</td>\n",
       "      <td>1.508211e+15</td>\n",
       "      <td>1.508211e+12</td>\n",
       "      <td>1.240000e+02</td>\n",
       "      <td>3.640460e+05</td>\n",
       "      <td>1.510603e+12</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>7.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id    session_id  session_start  session_size  \\\n",
       "count  2.988181e+06  2.988181e+06   2.988181e+06  2.988181e+06   \n",
       "mean   1.079478e+05  1.507472e+15   1.507472e+12  3.901885e+00   \n",
       "std    8.364836e+04  3.855245e+11   3.855245e+08  3.929941e+00   \n",
       "min    0.000000e+00  1.506825e+15   1.506825e+12  2.000000e+00   \n",
       "25%    4.034100e+04  1.507124e+15   1.507124e+12  2.000000e+00   \n",
       "50%    8.622900e+04  1.507493e+15   1.507493e+12  3.000000e+00   \n",
       "75%    1.632610e+05  1.507749e+15   1.507749e+12  4.000000e+00   \n",
       "max    3.228960e+05  1.508211e+15   1.508211e+12  1.240000e+02   \n",
       "\n",
       "       click_article_id  click_timestamp  click_environment  \\\n",
       "count      2.988181e+06     2.988181e+06       2.988181e+06   \n",
       "mean       1.949226e+05     1.507474e+12       3.942652e+00   \n",
       "std        9.076842e+04     3.858510e+08       3.396804e-01   \n",
       "min        3.000000e+00     1.506827e+12       1.000000e+00   \n",
       "25%        1.242280e+05     1.507127e+12       4.000000e+00   \n",
       "50%        2.023810e+05     1.507495e+12       4.000000e+00   \n",
       "75%        2.770670e+05     1.507751e+12       4.000000e+00   \n",
       "max        3.640460e+05     1.510603e+12       4.000000e+00   \n",
       "\n",
       "       click_deviceGroup      click_os  click_country  click_region  \\\n",
       "count       2.988181e+06  2.988181e+06   2.988181e+06  2.988181e+06   \n",
       "mean        1.819306e+00  1.327760e+01   1.357656e+00  1.831331e+01   \n",
       "std         1.042214e+00  6.881718e+00   1.725861e+00  7.064006e+00   \n",
       "min         1.000000e+00  2.000000e+00   1.000000e+00  1.000000e+00   \n",
       "25%         1.000000e+00  2.000000e+00   1.000000e+00  1.300000e+01   \n",
       "50%         1.000000e+00  1.700000e+01   1.000000e+00  2.100000e+01   \n",
       "75%         3.000000e+00  1.700000e+01   1.000000e+00  2.500000e+01   \n",
       "max         5.000000e+00  2.000000e+01   1.100000e+01  2.800000e+01   \n",
       "\n",
       "       click_referrer_type  \n",
       "count         2.988181e+06  \n",
       "mean          1.838981e+00  \n",
       "std           1.156356e+00  \n",
       "min           1.000000e+00  \n",
       "25%           1.000000e+00  \n",
       "50%           2.000000e+00  \n",
       "75%           2.000000e+00  \n",
       "max           7.000000e+00  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "click_df = click_df.astype('int')\n",
    "click_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3d342726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46033"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hashing article ids to prevent duplicates between user_id and click_article_id\n",
    "article_ids = click_df.click_article_id.unique()\n",
    "article_hashs = pd.util.hash_array(article_ids)\n",
    "\n",
    "index_to_hash = dict(zip(article_ids, article_hashs))\n",
    "hash_to_index = dict(zip(article_hashs, article_ids))\n",
    "\n",
    "len(hash_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f3a4b8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>session_start</th>\n",
       "      <th>session_size</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1506825423271737</td>\n",
       "      <td>1506825423000</td>\n",
       "      <td>2</td>\n",
       "      <td>1506826828020</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>11291614159970095935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1506825423271737</td>\n",
       "      <td>1506825423000</td>\n",
       "      <td>2</td>\n",
       "      <td>1506826858020</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1808725759962028682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1506825426267738</td>\n",
       "      <td>1506825426000</td>\n",
       "      <td>2</td>\n",
       "      <td>1506827017951</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>8060067950874265602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1506825426267738</td>\n",
       "      <td>1506825426000</td>\n",
       "      <td>2</td>\n",
       "      <td>1506827047951</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>8467875143793121792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1506825435299739</td>\n",
       "      <td>1506825435000</td>\n",
       "      <td>2</td>\n",
       "      <td>1506827090575</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>3839974878073404050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        session_id  session_start  session_size  click_timestamp  \\\n",
       "0        0  1506825423271737  1506825423000             2    1506826828020   \n",
       "1        0  1506825423271737  1506825423000             2    1506826858020   \n",
       "2        1  1506825426267738  1506825426000             2    1506827017951   \n",
       "3        1  1506825426267738  1506825426000             2    1506827047951   \n",
       "4        2  1506825435299739  1506825435000             2    1506827090575   \n",
       "\n",
       "   click_environment  click_deviceGroup  click_os  click_country  \\\n",
       "0                  4                  3        20              1   \n",
       "1                  4                  3        20              1   \n",
       "2                  4                  1        17              1   \n",
       "3                  4                  1        17              1   \n",
       "4                  4                  1        17              1   \n",
       "\n",
       "   click_region  click_referrer_type            article_id  \n",
       "0            20                    2  11291614159970095935  \n",
       "1            20                    2   1808725759962028682  \n",
       "2            16                    2   8060067950874265602  \n",
       "3            16                    2   8467875143793121792  \n",
       "4            24                    2   3839974878073404050  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "click_df['article_id'] = click_df['click_article_id'].apply(lambda x: index_to_hash[x])\n",
    "click_df.drop(columns='click_article_id', inplace=True)\n",
    "click_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5642f42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clicks</th>\n",
       "      <th>avg_session_size</th>\n",
       "      <th>env</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>region</th>\n",
       "      <th>ref_type</th>\n",
       "      <th>sessions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>3.117647</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322892</th>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322893</th>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322894</th>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322895</th>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322896</th>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>322897 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         clicks  avg_session_size  env  device  os  region  ref_type  sessions\n",
       "user_id                                                                       \n",
       "0             8          2.000000    4       3  20      20         2         4\n",
       "1            12          2.000000    4       1  17      17         2         6\n",
       "2             4          2.000000    4       1  17      24         2         2\n",
       "3            17          3.117647    4       3   2      21         1         6\n",
       "4             7          2.428571    4       1  17      17         1         3\n",
       "...         ...               ...  ...     ...  ..     ...       ...       ...\n",
       "322892        2          2.000000    4       1  12      16         1         1\n",
       "322893        2          2.000000    4       3   2      25         2         1\n",
       "322894        2          2.000000    4       3  20      25         2         1\n",
       "322895        2          2.000000    4       1  17      25         6         1\n",
       "322896        2          2.000000    4       1  17      25         2         1\n",
       "\n",
       "[322897 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generating user information:\n",
    "users = click_df.groupby('user_id').agg(clicks = ('session_id', pd.Series.count), avg_session_size = ('session_size', np.mean),\n",
    "                                        env = ('click_environment', st.mode), device = ('click_deviceGroup', st.mode),\n",
    "                                        os = ('click_os', st.mode), region = ('click_region', st.mode),\n",
    "                                        ref_type = ('click_referrer_type', st.mode), sessions = ('session_id', pd.Series.nunique))\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d23847d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>clicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>453242478275739747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1808725759962028682</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2329946091212022948</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2743957319142419568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3354362278157922163</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id           article_id  clicks\n",
       "0        0   453242478275739747       1\n",
       "1        0  1808725759962028682       1\n",
       "2        0  2329946091212022948       1\n",
       "3        0  2743957319142419568       1\n",
       "4        0  3354362278157922163       1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_matrix = click_df[['user_id','article_id','session_id']].groupby(['user_id','article_id']).count().reset_index()\n",
    "cf_matrix.rename(columns={'session_id': 'clicks'}, inplace=True)\n",
    "cf_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5f54a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     2916835\n",
       "2       31459\n",
       "3        1869\n",
       "4         343\n",
       "5          95\n",
       "6          42\n",
       "7          22\n",
       "8          14\n",
       "9           7\n",
       "10          7\n",
       "13          6\n",
       "12          3\n",
       "33          3\n",
       "16          2\n",
       "17          1\n",
       "30          1\n",
       "31          1\n",
       "Name: clicks, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_matrix['clicks'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6d364247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32555/2569374984.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clicks.rename(columns={'click_timestamp': 'timestamp'}, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11291614159970095935</td>\n",
       "      <td>1506826828020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1808725759962028682</td>\n",
       "      <td>1506826858020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8060067950874265602</td>\n",
       "      <td>1506827017951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8467875143793121792</td>\n",
       "      <td>1506827047951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3839974878073404050</td>\n",
       "      <td>1506827090575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988176</th>\n",
       "      <td>10051</td>\n",
       "      <td>9145846767463514897</td>\n",
       "      <td>1508211557302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988177</th>\n",
       "      <td>322896</td>\n",
       "      <td>11966379547785623297</td>\n",
       "      <td>1508211672520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988178</th>\n",
       "      <td>322896</td>\n",
       "      <td>17035819092917373661</td>\n",
       "      <td>1508211702520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988179</th>\n",
       "      <td>123718</td>\n",
       "      <td>13284560895759463907</td>\n",
       "      <td>1508211513583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988180</th>\n",
       "      <td>123718</td>\n",
       "      <td>7630374989610744636</td>\n",
       "      <td>1508211543583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2988181 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id            article_id      timestamp\n",
       "0              0  11291614159970095935  1506826828020\n",
       "1              0   1808725759962028682  1506826858020\n",
       "2              1   8060067950874265602  1506827017951\n",
       "3              1   8467875143793121792  1506827047951\n",
       "4              2   3839974878073404050  1506827090575\n",
       "...          ...                   ...            ...\n",
       "2988176    10051   9145846767463514897  1508211557302\n",
       "2988177   322896  11966379547785623297  1508211672520\n",
       "2988178   322896  17035819092917373661  1508211702520\n",
       "2988179   123718  13284560895759463907  1508211513583\n",
       "2988180   123718   7630374989610744636  1508211543583\n",
       "\n",
       "[2988181 rows x 3 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User click matrix that will be used because Pinsage requires a timestamp\n",
    "clicks = click_df[['user_id','article_id','click_timestamp']]\n",
    "clicks.rename(columns={'click_timestamp': 'timestamp'}, inplace=True)\n",
    "clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71a17ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.161183</td>\n",
       "      <td>-0.957233</td>\n",
       "      <td>-0.137944</td>\n",
       "      <td>0.050855</td>\n",
       "      <td>0.830055</td>\n",
       "      <td>0.901365</td>\n",
       "      <td>-0.335148</td>\n",
       "      <td>-0.559561</td>\n",
       "      <td>-0.500603</td>\n",
       "      <td>0.165183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321248</td>\n",
       "      <td>0.313999</td>\n",
       "      <td>0.636412</td>\n",
       "      <td>0.169179</td>\n",
       "      <td>0.540524</td>\n",
       "      <td>-0.813182</td>\n",
       "      <td>0.286870</td>\n",
       "      <td>-0.231686</td>\n",
       "      <td>0.597416</td>\n",
       "      <td>0.409623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.523216</td>\n",
       "      <td>-0.974058</td>\n",
       "      <td>0.738608</td>\n",
       "      <td>0.155234</td>\n",
       "      <td>0.626294</td>\n",
       "      <td>0.485297</td>\n",
       "      <td>-0.715657</td>\n",
       "      <td>-0.897996</td>\n",
       "      <td>-0.359747</td>\n",
       "      <td>0.398246</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.487843</td>\n",
       "      <td>0.823124</td>\n",
       "      <td>0.412688</td>\n",
       "      <td>-0.338654</td>\n",
       "      <td>0.320787</td>\n",
       "      <td>0.588643</td>\n",
       "      <td>-0.594137</td>\n",
       "      <td>0.182828</td>\n",
       "      <td>0.397090</td>\n",
       "      <td>-0.834364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.619619</td>\n",
       "      <td>-0.972960</td>\n",
       "      <td>-0.207360</td>\n",
       "      <td>-0.128861</td>\n",
       "      <td>0.044748</td>\n",
       "      <td>-0.387535</td>\n",
       "      <td>-0.730477</td>\n",
       "      <td>-0.066126</td>\n",
       "      <td>-0.754899</td>\n",
       "      <td>-0.242004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454756</td>\n",
       "      <td>0.473184</td>\n",
       "      <td>0.377866</td>\n",
       "      <td>-0.863887</td>\n",
       "      <td>-0.383365</td>\n",
       "      <td>0.137721</td>\n",
       "      <td>-0.810877</td>\n",
       "      <td>-0.447580</td>\n",
       "      <td>0.805932</td>\n",
       "      <td>-0.285284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.740843</td>\n",
       "      <td>-0.975749</td>\n",
       "      <td>0.391698</td>\n",
       "      <td>0.641738</td>\n",
       "      <td>-0.268645</td>\n",
       "      <td>0.191745</td>\n",
       "      <td>-0.825593</td>\n",
       "      <td>-0.710591</td>\n",
       "      <td>-0.040099</td>\n",
       "      <td>-0.110514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271535</td>\n",
       "      <td>0.036040</td>\n",
       "      <td>0.480029</td>\n",
       "      <td>-0.763173</td>\n",
       "      <td>0.022627</td>\n",
       "      <td>0.565165</td>\n",
       "      <td>-0.910286</td>\n",
       "      <td>-0.537838</td>\n",
       "      <td>0.243541</td>\n",
       "      <td>-0.885329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.279052</td>\n",
       "      <td>-0.972315</td>\n",
       "      <td>0.685374</td>\n",
       "      <td>0.113056</td>\n",
       "      <td>0.238315</td>\n",
       "      <td>0.271913</td>\n",
       "      <td>-0.568816</td>\n",
       "      <td>0.341194</td>\n",
       "      <td>-0.600554</td>\n",
       "      <td>-0.125644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238286</td>\n",
       "      <td>0.809268</td>\n",
       "      <td>0.427521</td>\n",
       "      <td>-0.615932</td>\n",
       "      <td>-0.503697</td>\n",
       "      <td>0.614450</td>\n",
       "      <td>-0.917760</td>\n",
       "      <td>-0.424061</td>\n",
       "      <td>0.185484</td>\n",
       "      <td>-0.580292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364042</th>\n",
       "      <td>-0.055038</td>\n",
       "      <td>-0.962136</td>\n",
       "      <td>0.869436</td>\n",
       "      <td>-0.071523</td>\n",
       "      <td>-0.725294</td>\n",
       "      <td>0.434320</td>\n",
       "      <td>0.198312</td>\n",
       "      <td>-0.581154</td>\n",
       "      <td>0.702346</td>\n",
       "      <td>-0.124813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410549</td>\n",
       "      <td>0.564252</td>\n",
       "      <td>-0.463959</td>\n",
       "      <td>0.167907</td>\n",
       "      <td>-0.480068</td>\n",
       "      <td>0.652090</td>\n",
       "      <td>0.380880</td>\n",
       "      <td>0.433195</td>\n",
       "      <td>-0.662455</td>\n",
       "      <td>-0.222850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364043</th>\n",
       "      <td>-0.136932</td>\n",
       "      <td>-0.995471</td>\n",
       "      <td>0.991298</td>\n",
       "      <td>0.031871</td>\n",
       "      <td>-0.915622</td>\n",
       "      <td>-0.658517</td>\n",
       "      <td>0.633090</td>\n",
       "      <td>-0.564356</td>\n",
       "      <td>0.676551</td>\n",
       "      <td>-0.446068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.681986</td>\n",
       "      <td>-0.574185</td>\n",
       "      <td>-0.536908</td>\n",
       "      <td>0.688934</td>\n",
       "      <td>0.528204</td>\n",
       "      <td>0.162435</td>\n",
       "      <td>0.940364</td>\n",
       "      <td>0.989298</td>\n",
       "      <td>-0.761595</td>\n",
       "      <td>-0.414652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364044</th>\n",
       "      <td>-0.251390</td>\n",
       "      <td>-0.976243</td>\n",
       "      <td>0.586097</td>\n",
       "      <td>0.643631</td>\n",
       "      <td>-0.663359</td>\n",
       "      <td>-0.093480</td>\n",
       "      <td>0.691553</td>\n",
       "      <td>-0.588281</td>\n",
       "      <td>0.902999</td>\n",
       "      <td>0.124571</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162220</td>\n",
       "      <td>-0.242030</td>\n",
       "      <td>-0.476131</td>\n",
       "      <td>0.352132</td>\n",
       "      <td>-0.311279</td>\n",
       "      <td>0.460574</td>\n",
       "      <td>-0.653077</td>\n",
       "      <td>-0.143725</td>\n",
       "      <td>0.068093</td>\n",
       "      <td>-0.705010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364045</th>\n",
       "      <td>0.224342</td>\n",
       "      <td>-0.923288</td>\n",
       "      <td>-0.381742</td>\n",
       "      <td>0.687890</td>\n",
       "      <td>-0.773911</td>\n",
       "      <td>-0.103629</td>\n",
       "      <td>-0.406486</td>\n",
       "      <td>0.246004</td>\n",
       "      <td>0.255191</td>\n",
       "      <td>-0.329587</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.422999</td>\n",
       "      <td>0.390324</td>\n",
       "      <td>0.655911</td>\n",
       "      <td>-0.646753</td>\n",
       "      <td>-0.174031</td>\n",
       "      <td>0.698037</td>\n",
       "      <td>-0.317102</td>\n",
       "      <td>0.687132</td>\n",
       "      <td>-0.531512</td>\n",
       "      <td>0.010726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364046</th>\n",
       "      <td>-0.257134</td>\n",
       "      <td>-0.994631</td>\n",
       "      <td>0.983792</td>\n",
       "      <td>-0.190975</td>\n",
       "      <td>-0.953720</td>\n",
       "      <td>-0.893823</td>\n",
       "      <td>0.708974</td>\n",
       "      <td>-0.557027</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>-0.118519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.490481</td>\n",
       "      <td>-0.689666</td>\n",
       "      <td>-0.661846</td>\n",
       "      <td>0.490945</td>\n",
       "      <td>0.736525</td>\n",
       "      <td>0.667668</td>\n",
       "      <td>0.902130</td>\n",
       "      <td>0.983873</td>\n",
       "      <td>-0.838183</td>\n",
       "      <td>-0.179283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364047 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6    \\\n",
       "0      -0.161183 -0.957233 -0.137944  0.050855  0.830055  0.901365 -0.335148   \n",
       "1      -0.523216 -0.974058  0.738608  0.155234  0.626294  0.485297 -0.715657   \n",
       "2      -0.619619 -0.972960 -0.207360 -0.128861  0.044748 -0.387535 -0.730477   \n",
       "3      -0.740843 -0.975749  0.391698  0.641738 -0.268645  0.191745 -0.825593   \n",
       "4      -0.279052 -0.972315  0.685374  0.113056  0.238315  0.271913 -0.568816   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "364042 -0.055038 -0.962136  0.869436 -0.071523 -0.725294  0.434320  0.198312   \n",
       "364043 -0.136932 -0.995471  0.991298  0.031871 -0.915622 -0.658517  0.633090   \n",
       "364044 -0.251390 -0.976243  0.586097  0.643631 -0.663359 -0.093480  0.691553   \n",
       "364045  0.224342 -0.923288 -0.381742  0.687890 -0.773911 -0.103629 -0.406486   \n",
       "364046 -0.257134 -0.994631  0.983792 -0.190975 -0.953720 -0.893823  0.708974   \n",
       "\n",
       "             7         8         9    ...       240       241       242  \\\n",
       "0      -0.559561 -0.500603  0.165183  ...  0.321248  0.313999  0.636412   \n",
       "1      -0.897996 -0.359747  0.398246  ... -0.487843  0.823124  0.412688   \n",
       "2      -0.066126 -0.754899 -0.242004  ...  0.454756  0.473184  0.377866   \n",
       "3      -0.710591 -0.040099 -0.110514  ...  0.271535  0.036040  0.480029   \n",
       "4       0.341194 -0.600554 -0.125644  ...  0.238286  0.809268  0.427521   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "364042 -0.581154  0.702346 -0.124813  ... -0.410549  0.564252 -0.463959   \n",
       "364043 -0.564356  0.676551 -0.446068  ... -0.681986 -0.574185 -0.536908   \n",
       "364044 -0.588281  0.902999  0.124571  ... -0.162220 -0.242030 -0.476131   \n",
       "364045  0.246004  0.255191 -0.329587  ... -0.422999  0.390324  0.655911   \n",
       "364046 -0.557027  0.846842 -0.118519  ... -0.490481 -0.689666 -0.661846   \n",
       "\n",
       "             243       244       245       246       247       248       249  \n",
       "0       0.169179  0.540524 -0.813182  0.286870 -0.231686  0.597416  0.409623  \n",
       "1      -0.338654  0.320787  0.588643 -0.594137  0.182828  0.397090 -0.834364  \n",
       "2      -0.863887 -0.383365  0.137721 -0.810877 -0.447580  0.805932 -0.285284  \n",
       "3      -0.763173  0.022627  0.565165 -0.910286 -0.537838  0.243541 -0.885329  \n",
       "4      -0.615932 -0.503697  0.614450 -0.917760 -0.424061  0.185484 -0.580292  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "364042  0.167907 -0.480068  0.652090  0.380880  0.433195 -0.662455 -0.222850  \n",
       "364043  0.688934  0.528204  0.162435  0.940364  0.989298 -0.761595 -0.414652  \n",
       "364044  0.352132 -0.311279  0.460574 -0.653077 -0.143725  0.068093 -0.705010  \n",
       "364045 -0.646753 -0.174031  0.698037 -0.317102  0.687132 -0.531512  0.010726  \n",
       "364046  0.490945  0.736525  0.667668  0.902130  0.983873 -0.838183 -0.179283  \n",
       "\n",
       "[364047 rows x 250 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_embeddings = pd.read_pickle('Data/articles_embeddings.pickle')\n",
    "article_embeddings = pd.DataFrame(article_embeddings)\n",
    "article_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "607323ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.740843</td>\n",
       "      <td>-0.975749</td>\n",
       "      <td>0.391698</td>\n",
       "      <td>0.641738</td>\n",
       "      <td>-0.268645</td>\n",
       "      <td>0.191745</td>\n",
       "      <td>-0.825593</td>\n",
       "      <td>-0.710591</td>\n",
       "      <td>-0.040099</td>\n",
       "      <td>-0.110514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271535</td>\n",
       "      <td>0.036040</td>\n",
       "      <td>0.480029</td>\n",
       "      <td>-0.763173</td>\n",
       "      <td>0.022627</td>\n",
       "      <td>0.565165</td>\n",
       "      <td>-0.910286</td>\n",
       "      <td>-0.537838</td>\n",
       "      <td>0.243541</td>\n",
       "      <td>-0.885329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.700814</td>\n",
       "      <td>-0.965927</td>\n",
       "      <td>-0.181869</td>\n",
       "      <td>-0.423504</td>\n",
       "      <td>-0.024668</td>\n",
       "      <td>0.187061</td>\n",
       "      <td>-0.674657</td>\n",
       "      <td>-0.108778</td>\n",
       "      <td>-0.762116</td>\n",
       "      <td>0.161282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165887</td>\n",
       "      <td>0.694188</td>\n",
       "      <td>0.495848</td>\n",
       "      <td>-0.629343</td>\n",
       "      <td>-0.231966</td>\n",
       "      <td>0.564555</td>\n",
       "      <td>-0.762103</td>\n",
       "      <td>-0.388876</td>\n",
       "      <td>0.696865</td>\n",
       "      <td>-0.532873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.093521</td>\n",
       "      <td>-0.981410</td>\n",
       "      <td>0.848944</td>\n",
       "      <td>0.530125</td>\n",
       "      <td>0.767768</td>\n",
       "      <td>0.067014</td>\n",
       "      <td>-0.764069</td>\n",
       "      <td>-0.238016</td>\n",
       "      <td>-0.504944</td>\n",
       "      <td>-0.215097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413857</td>\n",
       "      <td>-0.261328</td>\n",
       "      <td>-0.361129</td>\n",
       "      <td>-0.228905</td>\n",
       "      <td>-0.815412</td>\n",
       "      <td>-0.150129</td>\n",
       "      <td>-0.309511</td>\n",
       "      <td>-0.877652</td>\n",
       "      <td>0.643542</td>\n",
       "      <td>-0.908095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.221564</td>\n",
       "      <td>-0.978803</td>\n",
       "      <td>0.614596</td>\n",
       "      <td>-0.049789</td>\n",
       "      <td>0.159638</td>\n",
       "      <td>-0.029031</td>\n",
       "      <td>-0.716393</td>\n",
       "      <td>-0.287863</td>\n",
       "      <td>-0.622962</td>\n",
       "      <td>-0.040135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413513</td>\n",
       "      <td>0.150322</td>\n",
       "      <td>0.073361</td>\n",
       "      <td>-0.152517</td>\n",
       "      <td>-0.645792</td>\n",
       "      <td>0.680978</td>\n",
       "      <td>-0.519698</td>\n",
       "      <td>-0.248209</td>\n",
       "      <td>0.717366</td>\n",
       "      <td>-0.816945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-0.497972</td>\n",
       "      <td>-0.976125</td>\n",
       "      <td>0.812216</td>\n",
       "      <td>-0.591446</td>\n",
       "      <td>0.876975</td>\n",
       "      <td>0.338400</td>\n",
       "      <td>-0.701809</td>\n",
       "      <td>-0.711910</td>\n",
       "      <td>-0.168073</td>\n",
       "      <td>-0.162825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305283</td>\n",
       "      <td>0.269370</td>\n",
       "      <td>-0.393486</td>\n",
       "      <td>-0.001957</td>\n",
       "      <td>-0.736190</td>\n",
       "      <td>-0.202507</td>\n",
       "      <td>0.102859</td>\n",
       "      <td>-0.833087</td>\n",
       "      <td>0.780866</td>\n",
       "      <td>-0.817214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4         5    \\\n",
       "article_id                                                               \n",
       "3          -0.740843 -0.975749  0.391698  0.641738 -0.268645  0.191745   \n",
       "27         -0.700814 -0.965927 -0.181869 -0.423504 -0.024668  0.187061   \n",
       "69          0.093521 -0.981410  0.848944  0.530125  0.767768  0.067014   \n",
       "81          0.221564 -0.978803  0.614596 -0.049789  0.159638 -0.029031   \n",
       "84         -0.497972 -0.976125  0.812216 -0.591446  0.876975  0.338400   \n",
       "\n",
       "                 6         7         8         9    ...       240       241  \\\n",
       "article_id                                          ...                       \n",
       "3          -0.825593 -0.710591 -0.040099 -0.110514  ...  0.271535  0.036040   \n",
       "27         -0.674657 -0.108778 -0.762116  0.161282  ...  0.165887  0.694188   \n",
       "69         -0.764069 -0.238016 -0.504944 -0.215097  ...  0.413857 -0.261328   \n",
       "81         -0.716393 -0.287863 -0.622962 -0.040135  ...  0.413513  0.150322   \n",
       "84         -0.701809 -0.711910 -0.168073 -0.162825  ...  0.305283  0.269370   \n",
       "\n",
       "                 242       243       244       245       246       247  \\\n",
       "article_id                                                               \n",
       "3           0.480029 -0.763173  0.022627  0.565165 -0.910286 -0.537838   \n",
       "27          0.495848 -0.629343 -0.231966  0.564555 -0.762103 -0.388876   \n",
       "69         -0.361129 -0.228905 -0.815412 -0.150129 -0.309511 -0.877652   \n",
       "81          0.073361 -0.152517 -0.645792  0.680978 -0.519698 -0.248209   \n",
       "84         -0.393486 -0.001957 -0.736190 -0.202507  0.102859 -0.833087   \n",
       "\n",
       "                 248       249  \n",
       "article_id                      \n",
       "3           0.243541 -0.885329  \n",
       "27          0.696865 -0.532873  \n",
       "69          0.643542 -0.908095  \n",
       "81          0.717366 -0.816945  \n",
       "84          0.780866 -0.817214  \n",
       "\n",
       "[5 rows x 250 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing articles that have never been viewed\n",
    "article_embeddings = article_embeddings.loc[np.isin(article_embeddings.index, article_ids)]\n",
    "article_embeddings.index.names=['article_id']\n",
    "article_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "268157aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.650192</td>\n",
       "      <td>-6.480907</td>\n",
       "      <td>2.064866</td>\n",
       "      <td>5.082841</td>\n",
       "      <td>-3.380797</td>\n",
       "      <td>-2.340155</td>\n",
       "      <td>-1.427830</td>\n",
       "      <td>1.389152</td>\n",
       "      <td>-3.397414</td>\n",
       "      <td>-3.202608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-5.469023</td>\n",
       "      <td>0.475530</td>\n",
       "      <td>-2.765252</td>\n",
       "      <td>3.077699</td>\n",
       "      <td>0.266455</td>\n",
       "      <td>1.895195</td>\n",
       "      <td>0.158804</td>\n",
       "      <td>-2.471497</td>\n",
       "      <td>-0.182341</td>\n",
       "      <td>-2.185511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-1.885955</td>\n",
       "      <td>0.773400</td>\n",
       "      <td>5.380998</td>\n",
       "      <td>7.852194</td>\n",
       "      <td>-2.522724</td>\n",
       "      <td>-5.184396</td>\n",
       "      <td>-0.891740</td>\n",
       "      <td>-0.129523</td>\n",
       "      <td>1.495872</td>\n",
       "      <td>0.036295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-4.331629</td>\n",
       "      <td>-3.230770</td>\n",
       "      <td>2.532839</td>\n",
       "      <td>5.019308</td>\n",
       "      <td>-1.603548</td>\n",
       "      <td>-0.882981</td>\n",
       "      <td>0.372032</td>\n",
       "      <td>0.291674</td>\n",
       "      <td>2.287797</td>\n",
       "      <td>2.058283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-8.576113</td>\n",
       "      <td>1.457389</td>\n",
       "      <td>4.241724</td>\n",
       "      <td>6.394057</td>\n",
       "      <td>-1.539646</td>\n",
       "      <td>-4.219621</td>\n",
       "      <td>0.988904</td>\n",
       "      <td>-0.724019</td>\n",
       "      <td>-0.227235</td>\n",
       "      <td>-0.227007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364017</th>\n",
       "      <td>6.970361</td>\n",
       "      <td>-2.278356</td>\n",
       "      <td>2.121049</td>\n",
       "      <td>2.190492</td>\n",
       "      <td>5.018913</td>\n",
       "      <td>1.562907</td>\n",
       "      <td>2.153743</td>\n",
       "      <td>0.362998</td>\n",
       "      <td>4.199409</td>\n",
       "      <td>-0.950588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364022</th>\n",
       "      <td>1.539827</td>\n",
       "      <td>-2.404729</td>\n",
       "      <td>7.392335</td>\n",
       "      <td>7.124627</td>\n",
       "      <td>-0.143433</td>\n",
       "      <td>2.775937</td>\n",
       "      <td>3.272008</td>\n",
       "      <td>-1.668811</td>\n",
       "      <td>-0.030591</td>\n",
       "      <td>-0.497044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364028</th>\n",
       "      <td>5.444149</td>\n",
       "      <td>-4.763050</td>\n",
       "      <td>4.835867</td>\n",
       "      <td>7.219858</td>\n",
       "      <td>1.044802</td>\n",
       "      <td>-5.260777</td>\n",
       "      <td>-1.927793</td>\n",
       "      <td>4.750260</td>\n",
       "      <td>-0.445966</td>\n",
       "      <td>0.489683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364043</th>\n",
       "      <td>1.098172</td>\n",
       "      <td>4.098582</td>\n",
       "      <td>5.454210</td>\n",
       "      <td>-0.088733</td>\n",
       "      <td>14.366396</td>\n",
       "      <td>-2.522954</td>\n",
       "      <td>-1.754451</td>\n",
       "      <td>3.296041</td>\n",
       "      <td>3.329590</td>\n",
       "      <td>-4.083865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364046</th>\n",
       "      <td>1.806023</td>\n",
       "      <td>2.830468</td>\n",
       "      <td>6.551385</td>\n",
       "      <td>-1.463643</td>\n",
       "      <td>14.617769</td>\n",
       "      <td>-2.288880</td>\n",
       "      <td>-0.310638</td>\n",
       "      <td>2.167172</td>\n",
       "      <td>1.392284</td>\n",
       "      <td>-4.029255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46033 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3          4         5  \\\n",
       "article_id                                                                \n",
       "3          -1.650192 -6.480907  2.064866  5.082841  -3.380797 -2.340155   \n",
       "27         -5.469023  0.475530 -2.765252  3.077699   0.266455  1.895195   \n",
       "69         -1.885955  0.773400  5.380998  7.852194  -2.522724 -5.184396   \n",
       "81         -4.331629 -3.230770  2.532839  5.019308  -1.603548 -0.882981   \n",
       "84         -8.576113  1.457389  4.241724  6.394057  -1.539646 -4.219621   \n",
       "...              ...       ...       ...       ...        ...       ...   \n",
       "364017      6.970361 -2.278356  2.121049  2.190492   5.018913  1.562907   \n",
       "364022      1.539827 -2.404729  7.392335  7.124627  -0.143433  2.775937   \n",
       "364028      5.444149 -4.763050  4.835867  7.219858   1.044802 -5.260777   \n",
       "364043      1.098172  4.098582  5.454210 -0.088733  14.366396 -2.522954   \n",
       "364046      1.806023  2.830468  6.551385 -1.463643  14.617769 -2.288880   \n",
       "\n",
       "                   6         7         8         9  \n",
       "article_id                                          \n",
       "3          -1.427830  1.389152 -3.397414 -3.202608  \n",
       "27          0.158804 -2.471497 -0.182341 -2.185511  \n",
       "69         -0.891740 -0.129523  1.495872  0.036295  \n",
       "81          0.372032  0.291674  2.287797  2.058283  \n",
       "84          0.988904 -0.724019 -0.227235 -0.227007  \n",
       "...              ...       ...       ...       ...  \n",
       "364017      2.153743  0.362998  4.199409 -0.950588  \n",
       "364022      3.272008 -1.668811 -0.030591 -0.497044  \n",
       "364028     -1.927793  4.750260 -0.445966  0.489683  \n",
       "364043     -1.754451  3.296041  3.329590 -4.083865  \n",
       "364046     -0.310638  2.167172  1.392284 -4.029255  \n",
       "\n",
       "[46033 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Keeping our article ids in memory\n",
    "id_list = article_embeddings.index\n",
    "\n",
    "# Scaling the embeddings and applying PCA\n",
    "sc = StandardScaler()\n",
    "pca = PCA(n_components = 10)\n",
    "embeddings_red = pd.DataFrame(pca.fit_transform(sc.fit_transform(article_embeddings)))\n",
    "embeddings_red.index = id_list\n",
    "embeddings_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f737444c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "PC_values = np.arange(pca.n_components_) + 1\n",
    "plt.plot(PC_values, pca.explained_variance_ratio_, 'o-', linewidth=2, color='blue')\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.show()\n",
    "\n",
    "#We will keep 8 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d97b1668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.650186</td>\n",
       "      <td>-6.480663</td>\n",
       "      <td>2.065924</td>\n",
       "      <td>5.080905</td>\n",
       "      <td>-3.360470</td>\n",
       "      <td>-2.340394</td>\n",
       "      <td>-1.400393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-5.469001</td>\n",
       "      <td>0.475465</td>\n",
       "      <td>-2.764940</td>\n",
       "      <td>3.075776</td>\n",
       "      <td>0.275952</td>\n",
       "      <td>1.890299</td>\n",
       "      <td>0.161445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-1.885951</td>\n",
       "      <td>0.773259</td>\n",
       "      <td>5.381386</td>\n",
       "      <td>7.850230</td>\n",
       "      <td>-2.521175</td>\n",
       "      <td>-5.187003</td>\n",
       "      <td>-0.902923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-4.331635</td>\n",
       "      <td>-3.230383</td>\n",
       "      <td>2.533653</td>\n",
       "      <td>5.017323</td>\n",
       "      <td>-1.588625</td>\n",
       "      <td>-0.885438</td>\n",
       "      <td>0.387652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-8.576115</td>\n",
       "      <td>1.457644</td>\n",
       "      <td>4.242645</td>\n",
       "      <td>6.390883</td>\n",
       "      <td>-1.524464</td>\n",
       "      <td>-4.225189</td>\n",
       "      <td>1.004020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364017</th>\n",
       "      <td>6.970358</td>\n",
       "      <td>-2.278298</td>\n",
       "      <td>2.120638</td>\n",
       "      <td>2.192752</td>\n",
       "      <td>5.011426</td>\n",
       "      <td>1.570768</td>\n",
       "      <td>2.142181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364022</th>\n",
       "      <td>1.539843</td>\n",
       "      <td>-2.404893</td>\n",
       "      <td>7.391911</td>\n",
       "      <td>7.125454</td>\n",
       "      <td>-0.150935</td>\n",
       "      <td>2.776282</td>\n",
       "      <td>3.259777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364028</th>\n",
       "      <td>5.444166</td>\n",
       "      <td>-4.763789</td>\n",
       "      <td>4.834816</td>\n",
       "      <td>7.221160</td>\n",
       "      <td>1.022543</td>\n",
       "      <td>-5.260710</td>\n",
       "      <td>-1.973192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364043</th>\n",
       "      <td>1.098181</td>\n",
       "      <td>4.098289</td>\n",
       "      <td>5.453502</td>\n",
       "      <td>-0.086116</td>\n",
       "      <td>14.350638</td>\n",
       "      <td>-2.516929</td>\n",
       "      <td>-1.775622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364046</th>\n",
       "      <td>1.806036</td>\n",
       "      <td>2.830056</td>\n",
       "      <td>6.550342</td>\n",
       "      <td>-1.460089</td>\n",
       "      <td>14.595485</td>\n",
       "      <td>-2.280990</td>\n",
       "      <td>-0.340314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46033 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3          4         5  \\\n",
       "article_id                                                                \n",
       "3          -1.650186 -6.480663  2.065924  5.080905  -3.360470 -2.340394   \n",
       "27         -5.469001  0.475465 -2.764940  3.075776   0.275952  1.890299   \n",
       "69         -1.885951  0.773259  5.381386  7.850230  -2.521175 -5.187003   \n",
       "81         -4.331635 -3.230383  2.533653  5.017323  -1.588625 -0.885438   \n",
       "84         -8.576115  1.457644  4.242645  6.390883  -1.524464 -4.225189   \n",
       "...              ...       ...       ...       ...        ...       ...   \n",
       "364017      6.970358 -2.278298  2.120638  2.192752   5.011426  1.570768   \n",
       "364022      1.539843 -2.404893  7.391911  7.125454  -0.150935  2.776282   \n",
       "364028      5.444166 -4.763789  4.834816  7.221160   1.022543 -5.260710   \n",
       "364043      1.098181  4.098289  5.453502 -0.086116  14.350638 -2.516929   \n",
       "364046      1.806036  2.830056  6.550342 -1.460089  14.595485 -2.280990   \n",
       "\n",
       "                   6  \n",
       "article_id            \n",
       "3          -1.400393  \n",
       "27          0.161445  \n",
       "69         -0.902923  \n",
       "81          0.387652  \n",
       "84          1.004020  \n",
       "...              ...  \n",
       "364017      2.142181  \n",
       "364022      3.259777  \n",
       "364028     -1.973192  \n",
       "364043     -1.775622  \n",
       "364046     -0.340314  \n",
       "\n",
       "[46033 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying transformation with 7 components\n",
    "sc = StandardScaler()\n",
    "pca = PCA(n_components = 7)\n",
    "embeddings_red = pd.DataFrame(pca.fit_transform(sc.fit_transform(article_embeddings)))\n",
    "embeddings_red.index = id_list\n",
    "embeddings_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccc19c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1513144419000</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1405341936000</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1408667706000</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1408468313000</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1407071171000</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  category_id  created_at_ts  publisher_id  words_count\n",
       "0           0            0  1513144419000             0          168\n",
       "1           1            1  1405341936000             0          189\n",
       "2           2            1  1408667706000             0          250\n",
       "3           3            1  1408468313000             0          230\n",
       "4           4            1  1407071171000             0          162"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.read_csv('Data/articles_metadata.csv')\n",
    "\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2f5cad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            category_id  publisher_id  words_count\n",
       "article_id                                        \n",
       "0                     0             0          168\n",
       "1                     1             0          189\n",
       "2                     1             0          250\n",
       "3                     1             0          230\n",
       "4                     1             0          162"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.set_index('article_id', inplace=True)\n",
    "meta.drop(columns=['created_at_ts'], inplace=True)\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "eeacf655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2185194620014831856</th>\n",
       "      <td>-1.650186</td>\n",
       "      <td>-6.480663</td>\n",
       "      <td>2.065924</td>\n",
       "      <td>5.080905</td>\n",
       "      <td>-3.360470</td>\n",
       "      <td>-2.340394</td>\n",
       "      <td>-1.400393</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3622748380379877116</th>\n",
       "      <td>-5.469001</td>\n",
       "      <td>0.475465</td>\n",
       "      <td>-2.764940</td>\n",
       "      <td>3.075776</td>\n",
       "      <td>0.275952</td>\n",
       "      <td>1.890299</td>\n",
       "      <td>0.161445</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4725800167843106944</th>\n",
       "      <td>-1.885951</td>\n",
       "      <td>0.773259</td>\n",
       "      <td>5.381386</td>\n",
       "      <td>7.850230</td>\n",
       "      <td>-2.521175</td>\n",
       "      <td>-5.187003</td>\n",
       "      <td>-0.902923</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10031739448034038636</th>\n",
       "      <td>-4.331635</td>\n",
       "      <td>-3.230383</td>\n",
       "      <td>2.533653</td>\n",
       "      <td>5.017323</td>\n",
       "      <td>-1.588625</td>\n",
       "      <td>-0.885438</td>\n",
       "      <td>0.387652</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16394261569950477017</th>\n",
       "      <td>-8.576115</td>\n",
       "      <td>1.457644</td>\n",
       "      <td>4.242645</td>\n",
       "      <td>6.390883</td>\n",
       "      <td>-1.524464</td>\n",
       "      <td>-4.225189</td>\n",
       "      <td>1.004020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0         1         2         3         4  \\\n",
       "article_id                                                               \n",
       "2185194620014831856  -1.650186 -6.480663  2.065924  5.080905 -3.360470   \n",
       "3622748380379877116  -5.469001  0.475465 -2.764940  3.075776  0.275952   \n",
       "4725800167843106944  -1.885951  0.773259  5.381386  7.850230 -2.521175   \n",
       "10031739448034038636 -4.331635 -3.230383  2.533653  5.017323 -1.588625   \n",
       "16394261569950477017 -8.576115  1.457644  4.242645  6.390883 -1.524464   \n",
       "\n",
       "                             5         6  category_id  publisher_id  \\\n",
       "article_id                                                            \n",
       "2185194620014831856  -2.340394 -1.400393            1             0   \n",
       "3622748380379877116   1.890299  0.161445            1             0   \n",
       "4725800167843106944  -5.187003 -0.902923            1             0   \n",
       "10031739448034038636 -0.885438  0.387652            1             0   \n",
       "16394261569950477017 -4.225189  1.004020            1             0   \n",
       "\n",
       "                      words_count  \n",
       "article_id                         \n",
       "2185194620014831856           230  \n",
       "3622748380379877116           151  \n",
       "4725800167843106944           290  \n",
       "10031739448034038636          202  \n",
       "16394261569950477017          158  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = embeddings_red.merge(meta, left_index=True, right_index=True, how='inner')\n",
    "articles.index = articles.index.map(lambda x: index_to_hash[x])\n",
    "for c in [\"category_id\", \"publisher_id\", \"words_count\"]:\n",
    "    articles[c] = articles[c].astype('int')\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b27d7f",
   "metadata": {},
   "source": [
    "### Building the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "004af09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322897 46033 2950710\n"
     ]
    }
   ],
   "source": [
    "from graph_builder import *\n",
    "builder = PandasGraphBuilder()\n",
    "builder.add_entities(users.reset_index(), 'user_id', 'user')\n",
    "builder.add_entities(articles.reset_index(), 'article_id', 'article')\n",
    "builder.add_binary_relations(cf_matrix, 'user_id', 'article_id', 'read')\n",
    "builder.add_binary_relations(cf_matrix, 'article_id', 'user_id', 'read-by')\n",
    "g = builder.build()\n",
    "print(graph.number_of_nodes('user'), graph.number_of_nodes('article'), graph.number_of_edges('read'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "ade174ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign features.\n",
    "# Note that this code doesn't work on variable-size features like text or images\n",
    "\n",
    "user_catcols = [\"env\", \"device\", \"os\", \"region\", \"ref_type\"]\n",
    "user_floatcols = [\"avg_session_size\",\"clicks\",\"sessions\"]\n",
    "article_catcols = [\"category_id\", \"publisher_id\"]\n",
    "article_floatcols = list(range(7))+[\"words_count\"]\n",
    "\n",
    "for c in users.columns:\n",
    "    if c in user_catcols:\n",
    "        users[c] = users[c].astype(\"category\")\n",
    "        g.nodes[\"user\"].data[c] = torch.LongTensor(\n",
    "            users[c].cat.codes.values)\n",
    "# g.nodes[\"user\"].data[\"numcols\"] = torch.FloatTensor(\n",
    "#             users[user_floatcols].values)\n",
    "\n",
    "for c in articles.columns:\n",
    "    if c in article_catcols:\n",
    "        articles[c] = articles[c].astype(\"category\")\n",
    "        g.nodes[\"article\"].data[c] = torch.LongTensor(\n",
    "            articles[c].cat.codes.values\n",
    "        )\n",
    "# g.nodes[\"article\"].data[\"embedding\"] = torch.FloatTensor(\n",
    "#             articles[article_floatcols].values)\n",
    "\n",
    "g.edges[\"read\"].data[\"timestamp\"] = torch.LongTensor(\n",
    "    cf_matrix[\"clicks\"].values\n",
    ")\n",
    "g.edges[\"read-by\"].data[\"timestamp\"] = torch.LongTensor(\n",
    "    cf_matrix[\"clicks\"].values\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "5a323b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2065498 442606 442606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(cf_matrix, test_size=int(len(cf_matrix)*0.15), shuffle=True)\n",
    "train, val = train_test_split(train, test_size=int(len(cf_matrix)*0.15), shuffle=True)\n",
    "\n",
    "print(len(train), len(test), len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "f83101f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = list(train.index)\n",
    "test_indices = list(test.index)\n",
    "val_indices = list(val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "6f2e2c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import scipy.sparse as ssp\n",
    "import pickle\n",
    "\n",
    "def build_train_graph(g, train_indices, utype, itype, etype, etype_rev):\n",
    "    train_g = g.edge_subgraph({etype: train_indices, etype_rev: train_indices})\n",
    "\n",
    "\n",
    "#Since DGL update, features are automatically updated\n",
    "    for ntype in g.ntypes:\n",
    "        for col, data in g.nodes[ntype].data.items():\n",
    "            train_g.nodes[ntype].data[col] = data[train_g.nodes[ntype].data[dgl.NID]]\n",
    "    for etype in g.etypes:\n",
    "        for col, data in g.edges[etype].data.items():\n",
    "            train_g.edges[etype].data[col] = data[train_g.edges[etype].data[dgl.EID]]\n",
    "            \n",
    "    # remove the induced node IDs - should be assigned by model instead\n",
    "    del train_g.nodes[utype].data[dgl.NID]\n",
    "    del train_g.nodes[itype].data[dgl.NID]\n",
    "\n",
    "    return train_g\n",
    "\n",
    "def build_val_test_matrix(g, val_indices, test_indices, utype, itype, etype):\n",
    "    n_users = g.number_of_nodes(utype)\n",
    "    n_items = g.number_of_nodes(itype)\n",
    "    val_src, val_dst = g.find_edges(val_indices, etype=etype)\n",
    "    test_src, test_dst = g.find_edges(test_indices, etype=etype)\n",
    "    val_src = val_src.numpy()\n",
    "    val_dst = val_dst.numpy()\n",
    "    test_src = test_src.numpy()\n",
    "    test_dst = test_dst.numpy()\n",
    "    val_matrix = ssp.coo_matrix((np.ones_like(val_src), (val_src, val_dst)), (n_users, n_items))\n",
    "    test_matrix = ssp.coo_matrix((np.ones_like(test_src), (test_src, test_dst)), (n_users, n_items))\n",
    "\n",
    "    return val_matrix, test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "bed103fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g = build_train_graph(g, train_indices, \"user\", \"article\", \"read\", \"read-by\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "80de189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_matrix, test_matrix = build_val_test_matrix(\n",
    "    g, val_indices, test_indices, \"user\", \"article\", \"read\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "e25359d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgl.save_graphs('data/train_g.bin', train_g)\n",
    "\n",
    "dataset = {\n",
    "        \"val-matrix\": val_matrix,\n",
    "        \"test-matrix\": test_matrix,\n",
    "        \"item-texts\": articles.index.values,\n",
    "        \"item-images\": None,\n",
    "        \"user-type\": \"user\",\n",
    "        \"item-type\": \"article\",\n",
    "        \"user-to-item-type\": \"read\",\n",
    "        \"item-to-user-type\": \"read-by\",\n",
    "        \"timestamp-edge-column\": \"timestamp\"\n",
    "    }\n",
    "\n",
    "with open('data/data.pkl', 'wb') as f:\n",
    "    pickle.dump(dataset,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "2bdc8a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def prec(recommendations, ground_truth):\n",
    "    n_users, n_items = ground_truth.shape\n",
    "    K = recommendations.shape[1]\n",
    "    user_idx = np.repeat(np.arange(n_users), K)\n",
    "    item_idx = recommendations.flatten()\n",
    "    relevance = ground_truth[user_idx, item_idx].reshape((n_users, K))\n",
    "    hit = relevance.any(axis=1).mean()\n",
    "    return hit\n",
    "\n",
    "\n",
    "class LatestNNRecommender(object):\n",
    "    def __init__(\n",
    "        self, user_ntype, item_ntype, user_to_item_etype, timestamp, batch_size\n",
    "    ):\n",
    "        self.user_ntype = user_ntype\n",
    "        self.item_ntype = item_ntype\n",
    "        self.user_to_item_etype = user_to_item_etype\n",
    "        self.batch_size = batch_size\n",
    "        self.timestamp = timestamp\n",
    "\n",
    "    def recommend(self, full_graph, K, h_user, h_item):\n",
    "        \"\"\"\n",
    "        Return a (n_user, K) matrix of recommended items for each user\n",
    "        \"\"\"\n",
    "        graph_slice = full_graph.edge_type_subgraph([self.user_to_item_etype])\n",
    "        n_users = full_graph.num_nodes(self.user_ntype)\n",
    "        latest_interactions = dgl.sampling.select_topk(\n",
    "            graph_slice, 1, self.timestamp, edge_dir=\"out\"\n",
    "        )\n",
    "        user, latest_items = latest_interactions.all_edges(\n",
    "            form=\"uv\", order=\"srcdst\"\n",
    "        )\n",
    "        # each user should have at least one \"latest\" interaction\n",
    "        assert torch.equal(user, torch.arange(n_users))\n",
    "\n",
    "        recommended_batches = []\n",
    "        user_batches = torch.arange(n_users).split(self.batch_size)\n",
    "        for user_batch in user_batches:\n",
    "            latest_item_batch = latest_items[user_batch].to(\n",
    "                device=h_item.device\n",
    "            )\n",
    "            dist = h_item[latest_item_batch] @ h_item.t()\n",
    "            # exclude items that are already interacted\n",
    "            for i, u in enumerate(user_batch.tolist()):\n",
    "                interacted_items = full_graph.successors(\n",
    "                    u, etype=self.user_to_item_etype\n",
    "                )\n",
    "                dist[i, interacted_items] = -np.inf\n",
    "            recommended_batches.append(dist.topk(K, 1)[1])\n",
    "\n",
    "        recommendations = torch.cat(recommended_batches, 0)\n",
    "        return recommendations\n",
    "\n",
    "\n",
    "def evaluate_nn(dataset, h_item, k, batch_size):\n",
    "    g = dataset[\"train-graph\"]\n",
    "    val_matrix = dataset[\"val-matrix\"].tocsr()\n",
    "    test_matrix = dataset[\"test-matrix\"].tocsr()\n",
    "    item_texts = dataset[\"item-texts\"]\n",
    "    user_ntype = dataset[\"user-type\"]\n",
    "    item_ntype = dataset[\"item-type\"]\n",
    "    user_to_item_etype = dataset[\"user-to-item-type\"]\n",
    "    timestamp = dataset[\"timestamp-edge-column\"]\n",
    "\n",
    "    rec_engine = LatestNNRecommender(\n",
    "        user_ntype, item_ntype, user_to_item_etype, timestamp, batch_size\n",
    "    )\n",
    "\n",
    "    recommendations = rec_engine.recommend(g, k, None, h_item).cpu().numpy()\n",
    "    return prec(recommendations, val_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "b5c52aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "import dgl.nn.pytorch as dglnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def disable_grad(module):\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "def _init_input_modules(g, ntype, textset, hidden_dims):\n",
    "    # We initialize the linear projections of each input feature ``x`` as\n",
    "    # follows:\n",
    "    # * If ``x`` is a scalar integral feature, we assume that ``x`` is a categorical\n",
    "    #   feature, and assume the range of ``x`` is 0..max(x).\n",
    "    # * If ``x`` is a float one-dimensional feature, we assume that ``x`` is a\n",
    "    #   numeric vector.\n",
    "    # * If ``x`` is a field of a textset, we process it as bag of words.\n",
    "    module_dict = nn.ModuleDict()\n",
    "\n",
    "    for column, data in g.nodes[ntype].data.items():\n",
    "        if column == dgl.NID:\n",
    "            continue\n",
    "        if data.dtype == torch.float32:\n",
    "            assert data.ndim ==2\n",
    "            m = nn.Linear(data.shape[0], hidden_dims)\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            module_dict[column] = m\n",
    "        elif data.dtype == torch.int64:\n",
    "            assert data.ndim == 1\n",
    "            m = nn.Embedding(data.max() + 2, hidden_dims, padding_idx=-1)\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            module_dict[column] = m\n",
    "\n",
    "    if textset is not None:\n",
    "        for column, field in textset.items():\n",
    "            textlist, vocab, pad_var, batch_first = field\n",
    "            module_dict[column] = BagOfWords(vocab, hidden_dims)\n",
    "\n",
    "    return module_dict\n",
    "\n",
    "\n",
    "class BagOfWords(nn.Module):\n",
    "    def __init__(self, vocab, hidden_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb = nn.Embedding(\n",
    "            len(vocab.get_itos()),\n",
    "            hidden_dims,\n",
    "            padding_idx=vocab.get_stoi()[\"<pad>\"],\n",
    "        )\n",
    "        nn.init.xavier_uniform_(self.emb.weight)\n",
    "\n",
    "    def forward(self, x, length):\n",
    "        return self.emb(x).sum(1) / length.unsqueeze(1).float()\n",
    "\n",
    "\n",
    "class LinearProjector(nn.Module):\n",
    "    \"\"\"\n",
    "    Projects each input feature of the graph linearly and sums them up\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, full_graph, ntype, textset, hidden_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ntype = ntype\n",
    "        self.inputs = _init_input_modules(\n",
    "            full_graph, ntype, textset, hidden_dims\n",
    "        )\n",
    "\n",
    "    def forward(self, ndata):\n",
    "        projections = []\n",
    "        for feature, data in ndata.items():\n",
    "            if feature == dgl.NID or feature.endswith(\"__len\"):\n",
    "                # This is an additional feature indicating the length of the ``feature``\n",
    "                # column; we shouldn't process this.\n",
    "                continue\n",
    "\n",
    "            module = self.inputs[feature]\n",
    "            if isinstance(module, BagOfWords):\n",
    "                # Textual feature; find the length and pass it to the textual module.\n",
    "                length = ndata[feature + \"__len\"]\n",
    "                result = module(data, length)\n",
    "            else:\n",
    "                result = module(data)\n",
    "            projections.append(result)\n",
    "\n",
    "        return torch.stack(projections, 1).sum(1)\n",
    "\n",
    "\n",
    "class WeightedSAGEConv(nn.Module):\n",
    "    def __init__(self, input_dims, hidden_dims, output_dims, act=F.relu):\n",
    "        super().__init__()\n",
    "\n",
    "        self.act = act\n",
    "        self.Q = nn.Linear(input_dims, hidden_dims)\n",
    "        self.W = nn.Linear(input_dims + hidden_dims, output_dims)\n",
    "        self.reset_parameters()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        gain = nn.init.calculate_gain(\"relu\")\n",
    "        nn.init.xavier_uniform_(self.Q.weight, gain=gain)\n",
    "        nn.init.xavier_uniform_(self.W.weight, gain=gain)\n",
    "        nn.init.constant_(self.Q.bias, 0)\n",
    "        nn.init.constant_(self.W.bias, 0)\n",
    "\n",
    "    def forward(self, g, h, weights):\n",
    "        \"\"\"\n",
    "        g : graph\n",
    "        h : node features\n",
    "        weights : scalar edge weights\n",
    "        \"\"\"\n",
    "        h_src, h_dst = h\n",
    "        with g.local_scope():\n",
    "            g.srcdata[\"n\"] = self.act(self.Q(self.dropout(h_src)))\n",
    "            g.edata[\"w\"] = weights.float()\n",
    "            g.update_all(fn.u_mul_e(\"n\", \"w\", \"m\"), fn.sum(\"m\", \"n\"))\n",
    "            g.update_all(fn.copy_e(\"w\", \"m\"), fn.sum(\"m\", \"ws\"))\n",
    "            n = g.dstdata[\"n\"]\n",
    "            ws = g.dstdata[\"ws\"].unsqueeze(1).clamp(min=1)\n",
    "            z = self.act(self.W(self.dropout(torch.cat([n / ws, h_dst], 1))))\n",
    "            z_norm = z.norm(2, 1, keepdim=True)\n",
    "            z_norm = torch.where(\n",
    "                z_norm == 0, torch.tensor(1.0).to(z_norm), z_norm\n",
    "            )\n",
    "            z = z / z_norm\n",
    "            return z\n",
    "\n",
    "\n",
    "class SAGENet(nn.Module):\n",
    "    def __init__(self, hidden_dims, n_layers):\n",
    "        \"\"\"\n",
    "        g : DGLGraph\n",
    "            The user-item interaction graph.\n",
    "            This is only for finding the range of categorical variables.\n",
    "        item_textsets : torchtext.data.Dataset\n",
    "            The textual features of each item node.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(n_layers):\n",
    "            self.convs.append(\n",
    "                WeightedSAGEConv(hidden_dims, hidden_dims, hidden_dims)\n",
    "            )\n",
    "\n",
    "    def forward(self, blocks, h):\n",
    "        for layer, block in zip(self.convs, blocks):\n",
    "            h_dst = h[: block.num_nodes(\"DST/\" + block.ntypes[0])]\n",
    "            h = layer(block, (h, h_dst), block.edata[\"weights\"])\n",
    "        return h\n",
    "\n",
    "\n",
    "class ItemToItemScorer(nn.Module):\n",
    "    def __init__(self, full_graph, ntype):\n",
    "        super().__init__()\n",
    "\n",
    "        n_nodes = full_graph.num_nodes(ntype)\n",
    "        self.bias = nn.Parameter(torch.zeros(n_nodes, 1))\n",
    "\n",
    "    def _add_bias(self, edges):\n",
    "        bias_src = self.bias[edges.src[dgl.NID]]\n",
    "        bias_dst = self.bias[edges.dst[dgl.NID]]\n",
    "        return {\"s\": edges.data[\"s\"] + bias_src + bias_dst}\n",
    "\n",
    "    def forward(self, item_item_graph, h):\n",
    "        \"\"\"\n",
    "        item_item_graph : graph consists of edges connecting the pairs\n",
    "        h : hidden state of every node\n",
    "        \"\"\"\n",
    "        with item_item_graph.local_scope():\n",
    "            item_item_graph.ndata[\"h\"] = h\n",
    "            item_item_graph.apply_edges(fn.u_dot_v(\"h\", \"h\", \"s\"))\n",
    "            item_item_graph.apply_edges(self._add_bias)\n",
    "            pair_score = item_item_graph.edata[\"s\"]\n",
    "        return pair_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "fe899e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from torchtext.data.functional import numericalize_tokens_from_iterator\n",
    "\n",
    "\n",
    "def padding(array, yy, val):\n",
    "    \"\"\"\n",
    "    :param array: torch tensor array\n",
    "    :param yy: desired width\n",
    "    :param val: padded value\n",
    "    :return: padded array\n",
    "    \"\"\"\n",
    "    w = array.shape[0]\n",
    "    b = 0\n",
    "    bb = yy - b - w\n",
    "\n",
    "    return torch.nn.functional.pad(\n",
    "        array, pad=(b, bb), mode=\"constant\", value=val\n",
    "    )\n",
    "\n",
    "\n",
    "def compact_and_copy(frontier, seeds):\n",
    "    block = dgl.to_block(frontier, seeds)\n",
    "    for col, data in frontier.edata.items():\n",
    "        if col == dgl.EID:\n",
    "            continue\n",
    "        block.edata[col] = data[block.edata[dgl.EID]]\n",
    "    return block\n",
    "\n",
    "\n",
    "class ItemToItemBatchSampler(IterableDataset):\n",
    "    def __init__(self, g, user_type, item_type, batch_size):\n",
    "        self.g = g\n",
    "        self.user_type = user_type\n",
    "        self.item_type = item_type\n",
    "        self.user_to_item_etype = list(g.metagraph()[user_type][item_type])[0]\n",
    "        self.item_to_user_etype = list(g.metagraph()[item_type][user_type])[0]\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            heads = torch.randint(\n",
    "                0, self.g.num_nodes(self.item_type), (self.batch_size,)\n",
    "            )\n",
    "            tails = dgl.sampling.random_walk(\n",
    "                self.g,\n",
    "                heads,\n",
    "                metapath=[self.item_to_user_etype, self.user_to_item_etype],\n",
    "            )[0][:, 2]\n",
    "            neg_tails = torch.randint(\n",
    "                0, self.g.num_nodes(self.item_type), (self.batch_size,)\n",
    "            )\n",
    "\n",
    "            mask = tails != -1\n",
    "            yield heads[mask], tails[mask], neg_tails[mask]\n",
    "\n",
    "\n",
    "class NeighborSampler(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        g,\n",
    "        user_type,\n",
    "        item_type,\n",
    "        random_walk_length,\n",
    "        random_walk_restart_prob,\n",
    "        num_random_walks,\n",
    "        num_neighbors,\n",
    "        num_layers,\n",
    "    ):\n",
    "        self.g = g\n",
    "        self.user_type = user_type\n",
    "        self.item_type = item_type\n",
    "        self.user_to_item_etype = list(g.metagraph()[user_type][item_type])[0]\n",
    "        self.item_to_user_etype = list(g.metagraph()[item_type][user_type])[0]\n",
    "        self.samplers = [\n",
    "            dgl.sampling.PinSAGESampler(\n",
    "                g,\n",
    "                item_type,\n",
    "                user_type,\n",
    "                random_walk_length,\n",
    "                random_walk_restart_prob,\n",
    "                num_random_walks,\n",
    "                num_neighbors,\n",
    "            )\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "\n",
    "    def sample_blocks(self, seeds, heads=None, tails=None, neg_tails=None):\n",
    "        blocks = []\n",
    "        for sampler in self.samplers:\n",
    "            frontier = sampler(seeds)\n",
    "            if heads is not None:\n",
    "                eids = frontier.edge_ids(\n",
    "                    torch.cat([heads, heads]),\n",
    "                    torch.cat([tails, neg_tails]),\n",
    "                    return_uv=True,\n",
    "                )[2]\n",
    "                if len(eids) > 0:\n",
    "                    old_frontier = frontier\n",
    "                    frontier = dgl.remove_edges(old_frontier, eids)\n",
    "                    # print(old_frontier)\n",
    "                    # print(frontier)\n",
    "                    # print(frontier.edata['weights'])\n",
    "                    # frontier.edata['weights'] = old_frontier.edata['weights'][frontier.edata[dgl.EID]]\n",
    "            block = compact_and_copy(frontier, seeds)\n",
    "            seeds = block.srcdata[dgl.NID]\n",
    "            blocks.insert(0, block)\n",
    "        return blocks\n",
    "\n",
    "    def sample_from_item_pairs(self, heads, tails, neg_tails):\n",
    "        # Create a graph with positive connections only and another graph with negative\n",
    "        # connections only.\n",
    "        pos_graph = dgl.graph(\n",
    "            (heads, tails), num_nodes=self.g.num_nodes(self.item_type)\n",
    "        )\n",
    "        neg_graph = dgl.graph(\n",
    "            (heads, neg_tails), num_nodes=self.g.num_nodes(self.item_type)\n",
    "        )\n",
    "        pos_graph, neg_graph = dgl.compact_graphs([pos_graph, neg_graph])\n",
    "        seeds = pos_graph.ndata[dgl.NID]\n",
    "\n",
    "        blocks = self.sample_blocks(seeds, heads, tails, neg_tails)\n",
    "        return pos_graph, neg_graph, blocks\n",
    "\n",
    "\n",
    "def assign_simple_node_features(ndata, g, ntype, assign_id=False):\n",
    "    \"\"\"\n",
    "    Copies data to the given block from the corresponding nodes in the original graph.\n",
    "    \"\"\"\n",
    "    for col in g.nodes[ntype].data.keys():\n",
    "        if not assign_id and col == dgl.NID:\n",
    "            continue\n",
    "        induced_nodes = ndata[dgl.NID]\n",
    "        ndata[col] = g.nodes[ntype].data[col][induced_nodes]\n",
    "\n",
    "\n",
    "def assign_textual_node_features(ndata, textset, ntype):\n",
    "    \"\"\"\n",
    "    Assigns numericalized tokens from a torchtext dataset to given block.\n",
    "    The numericalized tokens would be stored in the block as node features\n",
    "    with the same name as ``field_name``.\n",
    "    The length would be stored as another node feature with name\n",
    "    ``field_name + '__len'``.\n",
    "    block : DGLGraph\n",
    "        First element of the compacted blocks, with \"dgl.NID\" as the\n",
    "        corresponding node ID in the original graph, hence the index to the\n",
    "        text dataset.\n",
    "        The numericalized tokens (and lengths if available) would be stored\n",
    "        onto the blocks as new node features.\n",
    "    textset : torchtext.data.Dataset\n",
    "        A torchtext dataset whose number of examples is the same as that\n",
    "        of nodes in the original graph.\n",
    "    \"\"\"\n",
    "    node_ids = ndata[dgl.NID].numpy()\n",
    "\n",
    "    for field_name, field in textset.items():\n",
    "        textlist, vocab, pad_var, batch_first = field\n",
    "\n",
    "        examples = [textlist[i] for i in node_ids]\n",
    "        ids_iter = numericalize_tokens_from_iterator(vocab, examples)\n",
    "\n",
    "        maxsize = max([len(textlist[i]) for i in node_ids])\n",
    "        ids = next(ids_iter)\n",
    "        x = torch.asarray([num for num in ids])\n",
    "        lengths = torch.tensor([len(x)])\n",
    "        tokens = padding(x, maxsize, pad_var)\n",
    "\n",
    "        for ids in ids_iter:\n",
    "            x = torch.asarray([num for num in ids])\n",
    "            l = torch.tensor([len(x)])\n",
    "            y = padding(x, maxsize, pad_var)\n",
    "            tokens = torch.vstack((tokens, y))\n",
    "            lengths = torch.cat((lengths, l))\n",
    "\n",
    "        if not batch_first:\n",
    "            tokens = tokens.t()\n",
    "\n",
    "        ndata[field_name] = tokens\n",
    "        ndata[field_name + \"__len\"] = lengths\n",
    "\n",
    "\n",
    "def assign_features_to_blocks(blocks, g, textset, ntype):\n",
    "    # For the first block (which is closest to the input), copy the features from\n",
    "    # the original graph as well as the texts.\n",
    "    assign_simple_node_features(blocks[0].srcdata, g, ntype)\n",
    "    assign_textual_node_features(blocks[0].srcdata, textset, ntype)\n",
    "    assign_simple_node_features(blocks[-1].dstdata, g, ntype)\n",
    "    assign_textual_node_features(blocks[-1].dstdata, textset, ntype)\n",
    "\n",
    "\n",
    "class PinSAGECollator(object):\n",
    "    def __init__(self, sampler, g, ntype, textset):\n",
    "        self.sampler = sampler\n",
    "        self.ntype = ntype\n",
    "        self.g = g\n",
    "        self.textset = textset\n",
    "\n",
    "    def collate_train(self, batches):\n",
    "        heads, tails, neg_tails = batches[0]\n",
    "        # Construct multilayer neighborhood via PinSAGE...\n",
    "        pos_graph, neg_graph, blocks = self.sampler.sample_from_item_pairs(\n",
    "            heads, tails, neg_tails\n",
    "        )\n",
    "        assign_features_to_blocks(blocks, self.g, self.textset, self.ntype)\n",
    "\n",
    "        return pos_graph, neg_graph, blocks\n",
    "\n",
    "    def collate_test(self, samples):\n",
    "        batch = torch.LongTensor(samples)\n",
    "        blocks = self.sampler.sample_blocks(batch)\n",
    "        assign_features_to_blocks(blocks, self.g, self.textset, self.ntype)\n",
    "        return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "d5d939d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "\n",
    "class PinSAGEModel(nn.Module):\n",
    "    def __init__(self, full_graph, ntype, textsets, hidden_dims, n_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.proj = LinearProjector(\n",
    "            full_graph, ntype, textsets, hidden_dims\n",
    "        )\n",
    "        self.sage = SAGENet(hidden_dims, n_layers)\n",
    "        self.scorer = ItemToItemScorer(full_graph, ntype)\n",
    "\n",
    "    def forward(self, pos_graph, neg_graph, blocks):\n",
    "        h_item = self.get_repr(blocks)\n",
    "        pos_score = self.scorer(pos_graph, h_item)\n",
    "        neg_score = self.scorer(neg_graph, h_item)\n",
    "        return (neg_score - pos_score + 1).clamp(min=0)\n",
    "\n",
    "    def get_repr(self, blocks):\n",
    "        h_item = self.proj(blocks[0].srcdata)\n",
    "        h_item_dst = self.proj(blocks[-1].dstdata)\n",
    "        return h_item_dst + self.sage(blocks, h_item)\n",
    "\n",
    "\n",
    "def train(dataset, args):\n",
    "    g = dataset[\"train-graph\"]\n",
    "    val_matrix = dataset[\"val-matrix\"].tocsr()\n",
    "    test_matrix = dataset[\"test-matrix\"].tocsr()\n",
    "    item_texts = dataset[\"item-texts\"]\n",
    "    user_ntype = dataset[\"user-type\"]\n",
    "    item_ntype = dataset[\"item-type\"]\n",
    "    user_to_item_etype = dataset[\"user-to-item-type\"]\n",
    "    timestamp = dataset[\"timestamp-edge-column\"]\n",
    "\n",
    "    device = torch.device(args.device)\n",
    "\n",
    "    # Assign user and movie IDs and use them as features (to learn an individual trainable\n",
    "    # embedding for each entity)\n",
    "    g.nodes[user_ntype].data[\"id\"] = torch.arange(g.num_nodes(user_ntype))\n",
    "    g.nodes[item_ntype].data[\"id\"] = torch.arange(g.num_nodes(item_ntype))\n",
    "\n",
    "    # Prepare torchtext dataset and Vocabulary\n",
    "    textset = {}\n",
    "    tokenizer = get_tokenizer(None)\n",
    "\n",
    "    textlist = []\n",
    "    batch_first = True\n",
    "\n",
    "    for i in range(g.num_nodes(item_ntype)):\n",
    "        for key in item_texts.keys():\n",
    "            l = tokenizer(item_texts[key][i].lower())\n",
    "            textlist.append(l)\n",
    "    for key, field in item_texts.items():\n",
    "        vocab2 = build_vocab_from_iterator(\n",
    "            textlist, specials=[\"<unk>\", \"<pad>\"]\n",
    "        )\n",
    "        textset[key] = (\n",
    "            textlist,\n",
    "            vocab2,\n",
    "            vocab2.get_stoi()[\"<pad>\"],\n",
    "            batch_first,\n",
    "        )\n",
    "\n",
    "    # Sampler\n",
    "    batch_sampler = ItemToItemBatchSampler(\n",
    "        g, user_ntype, item_ntype, args.batch_size\n",
    "    )\n",
    "    neighbor_sampler = NeighborSampler(\n",
    "        g,\n",
    "        user_ntype,\n",
    "        item_ntype,\n",
    "        args.random_walk_length,\n",
    "        args.random_walk_restart_prob,\n",
    "        args.num_random_walks,\n",
    "        args.num_neighbors,\n",
    "        args.num_layers,\n",
    "    )\n",
    "    collator = PinSAGECollator(\n",
    "        neighbor_sampler, g, item_ntype, textset\n",
    "    )\n",
    "    dataloader = DataLoader(\n",
    "        batch_sampler,\n",
    "        collate_fn=collator.collate_train,\n",
    "        num_workers=args.num_workers,\n",
    "    )\n",
    "    dataloader_test = DataLoader(\n",
    "        torch.arange(g.num_nodes(item_ntype)),\n",
    "        batch_size=args.batch_size,\n",
    "        collate_fn=collator.collate_test,\n",
    "        num_workers=args.num_workers,\n",
    "    )\n",
    "    dataloader_it = iter(dataloader)\n",
    "\n",
    "    # Model\n",
    "    model = PinSAGEModel(\n",
    "        g, item_ntype, textset, args.hidden_dims, args.num_layers\n",
    "    ).to(device)\n",
    "    # Optimizer\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    # For each batch of head-tail-negative triplets...\n",
    "    for epoch_id in range(args.num_epochs):\n",
    "        model.train()\n",
    "        for batch_id in tqdm.trange(args.batches_per_epoch):\n",
    "            pos_graph, neg_graph, blocks = next(dataloader_it)\n",
    "            # Copy to GPU\n",
    "            for i in range(len(blocks)):\n",
    "                blocks[i] = blocks[i].to(device)\n",
    "            pos_graph = pos_graph.to(device)\n",
    "            neg_graph = neg_graph.to(device)\n",
    "\n",
    "            loss = model(pos_graph, neg_graph, blocks).mean()\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            item_batches = torch.arange(g.num_nodes(item_ntype)).split(\n",
    "                args.batch_size\n",
    "            )\n",
    "            h_item_batches = []\n",
    "            for blocks in dataloader_test:\n",
    "                for i in range(len(blocks)):\n",
    "                    blocks[i] = blocks[i].to(device)\n",
    "\n",
    "                h_item_batches.append(model.get_repr(blocks))\n",
    "            h_item = torch.cat(h_item_batches, 0)\n",
    "\n",
    "            print(\n",
    "                evaluate_nn(dataset, h_item, args.k, args.batch_size)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "a7815c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PinSAGEModel(\n",
    "        train_g, 'article', None, args.hidden_dims, args.num_layers\n",
    "    ).to(args.device)\n",
    "\n",
    "batch_sampler = ItemToItemBatchSampler(\n",
    "    train_g, 'user', 'article', 32\n",
    ")\n",
    "\n",
    "neighbor_sampler = NeighborSampler(\n",
    "    train_g,\n",
    "    'user',\n",
    "    'article',\n",
    "    2,\n",
    "    0.5,\n",
    "    10,\n",
    "    3,\n",
    "    2,\n",
    ")\n",
    "collator = PinSAGECollator(\n",
    "    neighbor_sampler, train_g, 'user', {}\n",
    ")\n",
    "dataloader = DataLoader(\n",
    "    batch_sampler,\n",
    "    collate_fn=collator.collate_train,\n",
    "    num_workers=args.num_workers,\n",
    ")\n",
    "\n",
    "dataloader_it = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "2c42d4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Block(num_src_nodes=829, num_dst_nodes=283, num_edges=832),\n",
       " Block(num_src_nodes=283, num_dst_nodes=87, num_edges=244)]"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_graph, neg_graph, blocks = next(dataloader_it)\n",
    "for i in range(len(blocks)):\n",
    "    blocks[i] = blocks[i].to(args.device)\n",
    "pos_graph = pos_graph.to(args.device)\n",
    "neg_graph = neg_graph.to(args.device)\n",
    "blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "a230ecf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'env'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[535], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn-rec/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[514], line 22\u001b[0m, in \u001b[0;36mPinSAGEModel.forward\u001b[0;34m(self, pos_graph, neg_graph, blocks)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, pos_graph, neg_graph, blocks):\n\u001b[0;32m---> 22\u001b[0m     h_item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     pos_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscorer(pos_graph, h_item)\n\u001b[1;32m     24\u001b[0m     neg_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscorer(neg_graph, h_item)\n",
      "Cell \u001b[0;32mIn[514], line 28\u001b[0m, in \u001b[0;36mPinSAGEModel.get_repr\u001b[0;34m(self, blocks)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_repr\u001b[39m(\u001b[38;5;28mself\u001b[39m, blocks):\n\u001b[0;32m---> 28\u001b[0m     h_item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrcdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     h_item_dst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(blocks[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdstdata)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m h_item_dst \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msage(blocks, h_item)\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn-rec/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[517], line 83\u001b[0m, in \u001b[0;36mLinearProjector.forward\u001b[0;34m(self, ndata)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature \u001b[38;5;241m==\u001b[39m dgl\u001b[38;5;241m.\u001b[39mNID \u001b[38;5;129;01mor\u001b[39;00m feature\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__len\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# This is an additional feature indicating the length of the ``feature``\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# column; we shouldn't process this.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, BagOfWords):\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# Textual feature; find the length and pass it to the textual module.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     length \u001b[38;5;241m=\u001b[39m ndata[feature \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__len\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn-rec/lib/python3.10/site-packages/torch/nn/modules/container.py:461\u001b[0m, in \u001b[0;36mModuleDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;129m@_copy_to_script_wrapper\u001b[39m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Module:\n\u001b[0;32m--> 461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'env'"
     ]
    }
   ],
   "source": [
    "model(pos_graph, neg_graph, blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "e7035ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PinSAGEModel(\n",
       "  (proj): LinearProjector(\n",
       "    (inputs): ModuleDict(\n",
       "      (category_id): Embedding(317, 8, padding_idx=316)\n",
       "      (publisher_id): Embedding(2, 8, padding_idx=1)\n",
       "      (embedding): Linear(in_features=38055, out_features=8, bias=True)\n",
       "      (id): Embedding(38056, 8, padding_idx=38055)\n",
       "    )\n",
       "  )\n",
       "  (sage): SAGENet(\n",
       "    (convs): ModuleList(\n",
       "      (0-1): 2 x WeightedSAGEConv(\n",
       "        (Q): Linear(in_features=8, out_features=8, bias=True)\n",
       "        (W): Linear(in_features=16, out_features=8, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (scorer): ItemToItemScorer()\n",
       ")"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "c99c0e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train-graph\"] = train_g\n",
    "textual_data = [str(x) for x in articles.index.values]\n",
    "textual_dataset = {\"title\": textual_data}\n",
    "dataset[\"item-texts\"] = textual_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "01d9fb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64546"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "with open('config/args.json', 'rb') as file:\n",
    "    args = dotdict(json.load(file))\n",
    "\n",
    "args.batches_per_epoch = len(train_indices)//args.batch_size\n",
    "args.batches_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "45c518ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_walk_length': 2,\n",
       " 'random_walk_restart_prob': 0.5,\n",
       " 'num_random_walks': 10,\n",
       " 'num_neighbors': 3,\n",
       " 'num_layers': 2,\n",
       " 'hidden_dims': 8,\n",
       " 'batch_size': 32,\n",
       " 'device': 'cuda:0',\n",
       " 'num_epochs': 50,\n",
       " 'batches_per_epoch': 64546,\n",
       " 'num_workers': 0,\n",
       " 'lr': 3e-05,\n",
       " 'k': 10}"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.batch_size = 32\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafc8bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████▍                            | 38991/64546 [37:32<25:11, 16.90it/s]"
     ]
    }
   ],
   "source": [
    "train(dataset, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "314da3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_id torch.int64 torch.Size([38055])\n",
      "publisher_id torch.int64 torch.Size([38055])\n",
      "embedding torch.float32 torch.Size([38055, 8])\n",
      "id torch.int64 torch.Size([38055])\n"
     ]
    }
   ],
   "source": [
    "for column, data in train_g.nodes[\"article\"].data.items():\n",
    "    print(column, data.dtype, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad45d690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 GNN Rec",
   "language": "python",
   "name": "gnn-rec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
